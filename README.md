# Autonomous Wheelchair using NVIDIA Jetson Nano

![autonomous wheelchair for physically disabled](https://github.com/kabilan2003/Autonomous-wheelchair-using-jetson-nano-/assets/109456728/2736da3b-7f93-4251-8bdf-14c2634a4d44)

# Autonomous Wheelchair 


Welcome to the Autonomous Wheelchair project using NVIDIA Jetson Nano! This project aims to develop an intelligent and autonomous wheelchair using the powerful NVIDIA Jetson Nano platform. The goal is to enhance the mobility and independence of users with mobility impairments by enabling the wheelchair to navigate and avoid obstacles autonomously.

# Table of contents 

1. Introduction
2. Features
3. Hardware Requirements
4. Software Requirements
5. Installation
6. Usage
7. Contributing
8. License

# Introduction
The Autonomous Wheelchair project leverages the NVIDIA Jetson Nano, a high-performance, low-power AI platform, to process sensor data, perform real-time object detection, and make intelligent decisions for autonomous navigation. The project integrates a range of sensors, including depth sensors, LiDAR, and cameras, to perceive the environment and provide accurate obstacle detection and avoidance capabilities.

The wheelchair's autonomous navigation system is built upon a combination of perception, path planning, and control algorithms. Deep Learning models are employed for object recognition and localization, allowing the wheelchair to detect obstacles and create a dynamic map of the surrounding environment.

The wheelchair's autonomous navigation system is built upon a combination of perception, path planning, and control algorithms. Deep Learning models are employed for object recognition and localization, allowing the wheelchair to detect obstacles and create a dynamic map of the surrounding environment.

# Features

    1.Real-time obstacle detection and avoidance using deep learning models.
    2.Integration of multiple sensors for robust environmental perception.
    3.Dynamic mapping and path planning algorithms for smooth navigation.
    4.User-friendly interface for manual and autonomous control modes.
    5.Extensible architecture, allowing for easy integration of additional features.

# Hardware Requirements
1. NVIDIA Jetson Nano Developer Kit
2. Depth Sensors (e.g., Intel RealSense Depth Camera)
3. RPLidar sensor
4. Cameras (e.g., USB webcams)
5. Motorized Wheelchair
6. Power Supply for Jetson Nano and other components

# Software Requirements
1. NVIDIA Jetson Nano Developer Kit with ubuntu 20.04
2. ROS (Robot Operating System) noetic
3. Python 3
4. OpenCV
5. yplo object detection

# Installation
1.ubuntu 20.04 - https://github.com/Qengineering/Jetson-Nano-Ubuntu-20-image

2.ros- http://wiki.ros.org/noetic/Installation/Ubuntu

3.ros navigation stack - https://github.com/kabilan2003/navigation_stack.git

4.yolo object detection for ros - https://github.com/leggedrobotics/darknet_ros.git

# working model 

![WhatsApp Image 2023-07-31 at 9 26 19 PM](https://github.com/kabilan2003/navigation_stack/assets/109456728/d93806b2-2dca-43e1-a40d-83de2a9f35fd)

# isaac ros simulation for wheelchair in hospital environment 

![WhatsApp Image 2023-07-31 at 9 28 15 PM](https://github.com/kabilan2003/navigation_stack/assets/109456728/9e29ef4e-07ce-4ec0-bdf9-c6ff70239f03)

# Ros gazebo simulation 

![Screenshot from 2023-07-31 21-33-56](https://github.com/kabilan2003/navigation_stack/assets/109456728/c008f7f0-fc0a-42ee-8da9-96c7327c00f1)



 






   












